{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "entropic_semi-discrete_OT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BavWCfnlITf4"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from torch.autograd.variable import Variable\r\n",
        "from torchvision import transforms, datasets\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0ytkn3fIfUL"
      },
      "source": [
        "# load MNIST\r\n",
        "def mnist_data():\r\n",
        "    compose = transforms.Compose(\r\n",
        "        [transforms.ToTensor(),\r\n",
        "         transforms.Normalize((.5), (.5)) #, .5, .5\r\n",
        "        ])\r\n",
        "    out_dir = './dataset'\r\n",
        "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\r\n",
        "    \r\n",
        "# Load data\r\n",
        "mnistdata = mnist_data()\r\n",
        "\r\n",
        "# Generator\r\n",
        "class GeneratorNet(torch.nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    A three hidden-layer generative neural network\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self):\r\n",
        "        super(GeneratorNet, self).__init__()\r\n",
        "        n_features = 100\r\n",
        "        n_out = 784\r\n",
        "        \r\n",
        "        self.hidden0 = nn.Sequential(\r\n",
        "            nn.Linear(n_features, 256),\r\n",
        "            nn.LeakyReLU(0.2)\r\n",
        "        ).to(device)\r\n",
        "        self.hidden1 = nn.Sequential(            \r\n",
        "            nn.Linear(256, 512),\r\n",
        "            nn.LeakyReLU(0.2)\r\n",
        "        ).to(device)\r\n",
        "        self.hidden2 = nn.Sequential(\r\n",
        "            nn.Linear(512, 1024),\r\n",
        "            nn.LeakyReLU(0.2)\r\n",
        "        ).to(device)\r\n",
        "        \r\n",
        "        self.out = nn.Sequential(\r\n",
        "            nn.Linear(1024, n_out),\r\n",
        "            nn.Tanh()\r\n",
        "        ).to(device)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.hidden0(x)\r\n",
        "        x = self.hidden1(x)\r\n",
        "        x = self.hidden2(x)\r\n",
        "        x = self.out(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "# images to vector\r\n",
        "def images_to_vectors(images):\r\n",
        "    return images.view(images.size(0), 784).to(device)\r\n",
        "\r\n",
        "def vectors_to_images(vectors):\r\n",
        "    return vectors.view(vectors.size(0), 1, 28, 28)      \r\n",
        "\r\n",
        "def noise(size):\r\n",
        "    n = Variable(torch.randn(size, 100, device=device))\r\n",
        "    return n\r\n",
        "\r\n",
        "def batch_imshow(vector_batch):\r\n",
        "  imgs = vectors_to_images(vector_batch).clone().detach()\r\n",
        "  fig, axs = plt.subplots(1, 10)\r\n",
        "  for i in range(10):\r\n",
        "    axs[i].imshow(imgs[i,0,:,:])\r\n",
        "    axs[i].axis('off')\r\n",
        "  plt.show()\r\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3isylcnIjPQ"
      },
      "source": [
        "# discriminator definition\r\n",
        "class entropic_OT(nn.Module):    \r\n",
        "    def __init__(self, y, lambd):\r\n",
        "        super(entropic_OT, self).__init__()\r\n",
        "        self.yt = y.transpose(1,0).requires_grad_(False).to(device)\r\n",
        "        self.sy2 = torch.sum(self.yt**2,0,keepdim=True)\r\n",
        "        self.psi = nn.Parameter(torch.zeros(y.size(0),  device=device))\r\n",
        "        self.lambd = lambd\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        cxy = (torch.sum(input**2,1,keepdim=True) +  self.sy2 - 2*torch.matmul(input,self.yt))/self.yt.size(0)#(torch.sqrt(torch.sum(input**2,1,keepdim=True) +  self.sy2 - 2*torch.matmul(input,self.yt)))**self.p\r\n",
        "        # test = -self.lambd*torch.logsumexp((self.psi.unsqueeze(0)-cxy)/self.lambd,1)\r\n",
        "        # print(test.shape)\r\n",
        "        # print(cxy.shape)\r\n",
        "        # print(torch.max(cxy))\r\n",
        "        # print(torch.min(cxy))\r\n",
        "        # test = (self.psi.unsqueeze(0)-cxy)/self.lambd\r\n",
        "        # print(test.max(0))\r\n",
        "        # print(test.min(0))\r\n",
        "        # print(torch.max( -self.lambd*torch.logsumexp((self.psi.unsqueeze(0)-cxy)/self.lambd,1) ))\r\n",
        "        # print(torch.min( -self.lambd*torch.logsumexp((self.psi.unsqueeze(0)-cxy)/self.lambd,1) ))\r\n",
        "        if self.lambd > 0:\r\n",
        "            output = -self.lambd*torch.logsumexp((self.psi.unsqueeze(0)-cxy)/self.lambd,1)# + torch.mean(self.psi)\r\n",
        "        else:\r\n",
        "            output = torch.min(cxy - self.psi.unsqueeze(0),1)[0]\r\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD787BybIm6w"
      },
      "source": [
        "def train_discriminator(discriminator, optimizer, input_data):\r\n",
        "    # Reset gradients\r\n",
        "    optimizer.zero_grad()    \r\n",
        "    # Train\r\n",
        "    prediction = discriminator(input_data)\r\n",
        "    # Calculate error and backpropagate\r\n",
        "    error = -torch.mean(prediction)\r\n",
        "    error.backward() \r\n",
        "    # print(discriminator.psi.grad)\r\n",
        "    # Update weights with gradients\r\n",
        "    optimizer.step()    \r\n",
        "    # discriminator.psi.data-=torch.mean(discriminator.psi.data) # Return error and predictions for real and fake inputs\r\n",
        "\r\n",
        "    return error\r\n",
        "\r\n",
        "def train_generator(discriminator, optimizer, input_data):\r\n",
        "    optimizer.zero_grad()    # Sample noise and generate fake data\r\n",
        "    prediction = discriminator(input_data)    # Calculate error and backpropagate\r\n",
        "    error = torch.mean(prediction)\r\n",
        "    error.backward()    # Update weights with gradients\r\n",
        "    optimizer.step()    # Return error\r\n",
        "    return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU_DI17qNer_"
      },
      "source": [
        "# initializer generator and discriminator\r\n",
        "full_data = torch.utils.data.DataLoader(mnistdata, batch_size=5000, shuffle=True) ## mettre 60000 pour toute la BDD (plus lent)\r\n",
        "\r\n",
        "lambd = 0.01\r\n",
        "batch_data, _ = next(iter(full_data))\r\n",
        "print(batch_data.shape)\r\n",
        "discriminator = entropic_OT(images_to_vectors(batch_data), lambd)\r\n",
        "\r\n",
        "# for n_batch, (real_batch,_) in enumerate(full_data):\r\n",
        "#     print(images_to_vectors(real_batch).shape)\r\n",
        "#     print(torch.min(images_to_vectors(real_batch)))\r\n",
        "#     discriminator = entropic_OT(images_to_vectors(real_batch), lambd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PjH-fUXRQo2"
      },
      "source": [
        " generator = GeneratorNet()\r\n",
        "\r\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.2)\r\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJJcttZwMpZ-"
      },
      "source": [
        "# Total number of epochs to train\r\n",
        "num_epochs = 1000\r\n",
        "batch_size = 200\r\n",
        "n_iter_psi = 100\r\n",
        "# discriminator.lambd = 0.1\r\n",
        "T = time.time()\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "   \r\n",
        "\r\n",
        "    # 1. Train Discriminator\r\n",
        "    d_optimizer = optim.ASGD(discriminator.parameters(), lr=0.8, alpha=0.5, t0=1)\r\n",
        "    for it in range(n_iter_psi):\r\n",
        "        fake_data = generator(noise(batch_size)).detach()      \r\n",
        "        # Train D\r\n",
        "        d_error = train_discriminator(discriminator, d_optimizer, fake_data)\r\n",
        "    discriminator.psi.data = d_optimizer.state[discriminator.psi]['ax']\r\n",
        "    discriminator.psi.data-=torch.mean(discriminator.psi.data)\r\n",
        "    # 2. Train Generator        \r\n",
        "    # Generate fake data\r\n",
        "    fake_data = generator(noise(batch_size))        \r\n",
        "    # Train G\r\n",
        "    g_error = train_generator(discriminator, g_optimizer, fake_data)        \r\n",
        "\r\n",
        "    # print('epoch time = '+str(time.time()-T)+'s')\r\n",
        "    # plot\r\n",
        "    if epoch % 10 == 0:\r\n",
        "        # discriminator.lambd *= 0.5\r\n",
        "        print(\"epoch {}:\".format(epoch))\r\n",
        "        print(\"Lambda = {}:\".format(discriminator.lambd))\r\n",
        "        print(\"Elapsed time {}:\".format(time.time()-T))\r\n",
        "        print('G error : {:4f}'.format(g_error.item()))\r\n",
        "        print('D error : {:4f}'.format(d_error.item()))\r\n",
        "        print(discriminator.psi)\r\n",
        "        batch_imshow(fake_data.cpu())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skCC3c5yOUW1"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}